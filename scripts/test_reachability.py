"""æµ‹è¯•ç¯å¢ƒä¸­çš„å¯è¾¾æ€§ç»Ÿè®¡è„šæœ¬

è¯¥è„šæœ¬åˆ†æå½“å‰ç¯å¢ƒä¸­çš„äººå‘˜å¯è¾¾æ€§ç»Ÿè®¡ï¼ŒåŒ…æ‹¬ï¼š
- ç»“æ„æ€§ä¸å¯è¾¾äººæ•°ç»Ÿè®¡
- Mismatch Rateï¼šæ¬§æ°æœ€è¿‘ç«™ â‰  æ­¥è¡Œè·¯ç½‘æœ€è¿‘ç«™çš„æ¯”ä¾‹
- Barrier Impactï¼šå› éš”ç¦»å¸¦/æ²³æµå¯¼è‡´çš„ä¸å¯è¾¾ç»Ÿè®¡
"""

from __future__ import annotations

import json
import sys
from pathlib import Path
from typing import Dict, List, Tuple

import pandas as pd

REPO_ROOT = Path(__file__).resolve().parents[1]
if str(REPO_ROOT) not in sys.path:
    sys.path.insert(0, str(REPO_ROOT))

from src.utils.config import load_config


def load_od_mapping_audit(audit_path: Path) -> Dict:
    """åŠ è½½ODæ˜ å°„å®¡è®¡æŠ¥å‘Š"""
    if not audit_path.exists():
        raise FileNotFoundError(f"ODæ˜ å°„å®¡è®¡æŠ¥å‘Šä¸å­˜åœ¨: {audit_path}")
    
    with open(audit_path, 'r', encoding='utf-8') as f:
        return json.load(f)


def load_graph_audit(audit_path: Path) -> Dict:
    """åŠ è½½å›¾æ„å»ºå®¡è®¡æŠ¥å‘Š"""
    if not audit_path.exists():
        raise FileNotFoundError(f"å›¾æ„å»ºå®¡è®¡æŠ¥å‘Šä¸å­˜åœ¨: {audit_path}")
    
    with open(audit_path, 'r', encoding='utf-8') as f:
        return json.load(f)


def calculate_total_statistics(audit_data: Dict) -> Dict:
    """è®¡ç®—æ€»ä½“ç»Ÿè®¡ä¿¡æ¯"""
    files = audit_data.get("files", [])
    
    total_rows = sum(file.get("rows", 0) for file in files)
    total_unreachable = sum(file.get("structural_unreachability_count", 0) for file in files)
    total_barrier_impact = sum(file.get("barrier_impact_count", 0) for file in files)
    
    # è®¡ç®—åŠ æƒå¹³å‡çš„mismatch rate
    weighted_mismatch_rate = sum(
        file.get("mismatch_rate", 0) * file.get("rows", 0) 
        for file in files
    ) / total_rows if total_rows > 0 else 0
    
    # è®¡ç®—åŠ æƒå¹³å‡çš„ä¸å¯è¾¾ç‡
    weighted_unreach_rate = sum(
        file.get("structural_unreachability_rate", 0) * file.get("rows", 0) 
        for file in files
    ) / total_rows if total_rows > 0 else 0
    
    # è®¡ç®—åŠ æƒå¹³å‡çš„barrier impactç‡
    weighted_barrier_rate = sum(
        file.get("barrier_impact_rate", 0) * file.get("rows", 0) 
        for file in files
    ) / total_rows if total_rows > 0 else 0
    
    return {
        "total_requests": total_rows,
        "total_structural_unreachable": total_unreachable,
        "total_barrier_impacted": total_barrier_impact,
        "total_reachable": total_rows - total_unreachable,
        "weighted_mismatch_rate": weighted_mismatch_rate,
        "weighted_structural_unreach_rate": weighted_unreach_rate,
        "weighted_barrier_impact_rate": weighted_barrier_rate,
        "reachable_percentage": (total_rows - total_unreachable) / total_rows * 100 if total_rows > 0 else 0,
        "unreachable_percentage": total_unreachable / total_rows * 100 if total_rows > 0 else 0
    }


def print_summary(total_stats: Dict, graph_audit: Dict):
    """æ‰“å°ç»Ÿè®¡æ‘˜è¦"""
    print("=" * 80)
    print("                    å¯è¾¾æ€§æµ‹è¯•æŠ¥å‘Š")
    print("=" * 80)
    
    print(f"\nğŸ“Š åŸºç¡€ç»Ÿè®¡:")
    print(f"  æ€»è¯·æ±‚æ•°: {total_stats['total_requests']:,}")
    print(f"  å¯è¾¾äººæ•°: {total_stats['total_reachable']:,} ({total_stats['reachable_percentage']:.2f}%)")
    print(f"  ç»“æ„æ€§ä¸å¯è¾¾äººæ•°: {total_stats['total_structural_unreachable']:,} ({total_stats['unreachable_percentage']:.2f}%)")
    
    print(f"\nğŸš§ Mismatch Rate (æ¬§æ° vs è·¯ç½‘æœ€è¿‘ç«™ä¸ä¸€è‡´):")
    print(f"  åŠ æƒå¹³å‡Mismatch Rate: {total_stats['weighted_mismatch_rate']:.4f} ({total_stats['weighted_mismatch_rate']*100:.2f}%)")
    print(f"  è¯´æ˜: è¯æ˜äº†Voronoiæ˜ å°„çš„å¿…è¦æ€§ï¼Œ{total_stats['weighted_mismatch_rate']*100:.1f}%çš„è¯·æ±‚æ¬§æ°æœ€è¿‘ç«™ä¸æ­¥è¡Œè·¯ç½‘æœ€è¿‘ç«™ä¸åŒ")
    
    print(f"\nğŸŒŠ Barrier Impact (éš”ç¦»å¸¦/æ²³æµå½±å“):")
    print(f"  å—å±éšœå½±å“è¯·æ±‚æ•°: {total_stats['total_barrier_impacted']:,}")
    print(f"  åŠ æƒå¹³å‡Barrier Impact Rate: {total_stats['weighted_barrier_impact_rate']:.6f} ({total_stats['weighted_barrier_impact_rate']*100:.4f}%)")
    print(f"  è¯´æ˜: å› åœ°ç†å±éšœå¯¼è‡´æ­¥è¡Œè·ç¦»æ˜¾è‘—å¢åŠ çš„è¯·æ±‚æ¯”ä¾‹")
    
    print(f"\nğŸ—ºï¸ ç½‘ç»œç»Ÿè®¡:")
    print(f"  è½¦ç«™æ•°é‡: {graph_audit.get('node_count', 'N/A')}")
    print(f"  è¾¹æ•°é‡: {graph_audit.get('edge_count', 'N/A')}")
    print(f"  æ˜¯å¦å¼±è¿é€š: {'æ˜¯' if graph_audit.get('weakly_connected', False) else 'å¦'}")
    print(f"  æ˜¯å¦å¼ºè¿é€š: {'æ˜¯' if graph_audit.get('strongly_connected', False) else 'å¦'}")
    
    print(f"\nğŸ“ˆ å¯è¾¾æ€§åˆ†æ:")
    if total_stats['unreachable_percentage'] < 1:
        print("  âœ… å¯è¾¾æ€§è‰¯å¥½: ä¸å¯è¾¾ç‡ä½äº1%")
    elif total_stats['unreachable_percentage'] < 5:
        print("  âš ï¸  å¯è¾¾æ€§ä¸€èˆ¬: ä¸å¯è¾¾ç‡åœ¨1-5%ä¹‹é—´")
    else:
        print("  âŒ å¯è¾¾æ€§è¾ƒå·®: ä¸å¯è¾¾ç‡è¶…è¿‡5%")
    
    if total_stats['weighted_mismatch_rate'] > 0.3:
        print("  âœ… Voronoiæ˜ å°„ä»·å€¼é«˜: Mismatch Rateè¶…è¿‡30%ï¼Œè¯æ˜ç½‘ç»œæ˜ å°„å¿…è¦æ€§")
    else:
        print("  ğŸ“ Voronoiæ˜ å°„ä»æœ‰ä»·å€¼: å³ä½¿Mismatch Rateè¾ƒä½ï¼Œä»èƒ½æé«˜ç²¾åº¦")
    
    print("\n" + "=" * 80)


def print_detailed_breakdown(audit_data: Dict):
    """æ‰“å°è¯¦ç»†åˆ†é¡¹ç»Ÿè®¡"""
    print("\nğŸ“‹ è¯¦ç»†åˆ†é¡¹ç»Ÿè®¡:")
    print("-" * 60)
    
    files = audit_data.get("files", [])
    for i, file in enumerate(files, 1):
        file_name = Path(file.get("input_path", "")).name
        print(f"\næ–‡ä»¶ {i}: {file_name}")
        print(f"  è¯·æ±‚æ•°: {file.get('rows', 0):,}")
        print(f"  Mismatch Rate: {file.get('mismatch_rate', 0):.4f} ({file.get('mismatch_rate', 0)*100:.2f}%)")
        print(f"  ç»“æ„æ€§ä¸å¯è¾¾: {file.get('structural_unreachability_count', 0)} ({file.get('structural_unreachability_rate', 0)*100:.3f}%)")
        print(f"    - ä¸Šè½¦ç‚¹ä¸å¯è¾¾: {file.get('pickup_structural_unreachability_count', 0)}")
        print(f"    - ä¸‹è½¦ç‚¹ä¸å¯è¾¾: {file.get('dropoff_structural_unreachability_count', 0)}")
        print(f"  å±éšœå½±å“: {file.get('barrier_impact_count', 0)} ({file.get('barrier_impact_rate', 0)*100:.4f}%)")
        print(f"    - ä¸Šè½¦ç‚¹å±éšœ: {file.get('pickup_barrier_impact_count', 0)}")
        print(f"    - ä¸‹è½¦ç‚¹å±éšœ: {file.get('dropoff_barrier_impact_count', 0)}")


def analyze_reachability_trends(audit_data: Dict) -> Dict:
    """åˆ†æå¯è¾¾æ€§è¶‹åŠ¿"""
    files = audit_data.get("files", [])
    if len(files) < 2:
        return {"trend": "insufficient_data"}
    
    # æ¯”è¾ƒç¬¬ä¸€ä¸ªå’Œæœ€åä¸€ä¸ªæ–‡ä»¶
    first_file = files[0]
    last_file = files[-1]
    
    trends = {
        "mismatch_trend": "stable",
        "unreach_trend": "stable", 
        "barrier_trend": "stable"
    }
    
    # è®¡ç®—å˜åŒ–
    mismatch_change = last_file.get('mismatch_rate', 0) - first_file.get('mismatch_rate', 0)
    unreach_change = last_file.get('structural_unreachability_rate', 0) - first_file.get('structural_unreachability_rate', 0)
    barrier_change = last_file.get('barrier_impact_rate', 0) - first_file.get('barrier_impact_rate', 0)
    
    # åˆ¤æ–­è¶‹åŠ¿ (å˜åŒ–è¶…è¿‡0.1%è®¤ä¸ºæœ‰æ˜¾è‘—å˜åŒ–)
    if abs(mismatch_change) > 0.001:
        trends["mismatch_trend"] = "increasing" if mismatch_change > 0 else "decreasing"
    if abs(unreach_change) > 0.0001:
        trends["unreach_trend"] = "increasing" if unreach_change > 0 else "decreasing"
    if abs(barrier_change) > 0.00001:
        trends["barrier_trend"] = "increasing" if barrier_change > 0 else "decreasing"
    
    return trends


def main():
    """ä¸»å‡½æ•°"""
    config_path = "configs/manhattan.yaml"
    
    try:
        cfg = load_config(config_path)
        paths_cfg = cfg.get("paths", {})
        
        od_audit_path = Path(paths_cfg.get("od_audit_path", "reports/audit/od_mapping.json"))
        graph_audit_path = Path(paths_cfg.get("graph_audit_path", "reports/audit/graph_build.json"))
        
        # åŠ è½½å®¡è®¡æ•°æ®
        od_audit = load_od_mapping_audit(od_audit_path)
        graph_audit = load_graph_audit(graph_audit_path)
        
        # è®¡ç®—æ€»ä½“ç»Ÿè®¡
        total_stats = calculate_total_statistics(od_audit)
        
        # æ‰“å°æŠ¥å‘Š
        print_summary(total_stats, graph_audit)
        print_detailed_breakdown(od_audit)
        
        # åˆ†æè¶‹åŠ¿
        trends = analyze_reachability_trends(od_audit)
        if trends.get("trend") != "insufficient_data":
            print(f"\nğŸ“ˆ è¶‹åŠ¿åˆ†æ:")
            print(f"  Mismatch Rateè¶‹åŠ¿: {trends['mismatch_trend']}")
            print(f"  ä¸å¯è¾¾ç‡è¶‹åŠ¿: {trends['unreach_trend']}")
            print(f"  å±éšœå½±å“è¶‹åŠ¿: {trends['barrier_trend']}")
        
        print(f"\nğŸ“„ è¯¦ç»†æ•°æ®æ–‡ä»¶:")
        print(f"  ODæ˜ å°„å®¡è®¡: {od_audit_path}")
        print(f"  å›¾æ„å»ºå®¡è®¡: {graph_audit_path}")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        print("\nğŸ’¡ æç¤º: è¯·ç¡®ä¿å·²è¿è¡Œå›¾æ„å»ºå’ŒODæ˜ å°„è„šæœ¬")
        print("   è¿è¡Œå‘½ä»¤:")
        print("   python scripts/build_graph.py --config configs/manhattan.yaml")
        print("   python scripts/map_od.py --config configs/manhattan.yaml")
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())
